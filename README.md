# З Agent Basics: LangChain + MCP

Este repo re煤ne ejemplos m铆nimos para comprender c贸mo LangChain orquesta agentes y c贸mo el protocolo MCP (Model Context Protocol) expone herramientas externas que los LLM pueden invocar de forma segura.

---

##  Conceptos express

- **LangChain** ([docs](https://python.langchain.com)): framework para encadenar LLMs con memoria, prompts y herramientas. Sus agentes deciden cu谩ndo llamar funciones externas y c贸mo razonar paso a paso.
- **MCP (Model Context Protocol)** ([spec](https://modelcontextprotocol.io/)): est谩ndar abierto para anunciar herramientas (APIs, scripts, DBs) a los modelos. Define c贸mo descubrir, describir y ejecutar capacidades v铆a transporte `stdio`, WebSockets, etc.
- **Adapters LangChainMCP**: permiten que un agente de LangChain trate a un servidor MCP como un paquete de `tools`, de modo que pueda ejecutarlos igual que cualquier otra funci贸n instrumentada.

---

##  Qu茅 hay en este repo

- `mcp_sample/mcp_server_local/server_local.py`: servidor MCP local (FastMCP) con cinco herramientas  suma, resta, multiplicaci贸n, divisi贸n con validaci贸n y un saludo (`hello-mcp`). Ideal para ver c贸mo se tipan par谩metros con `typing.Annotated`.
- `mcp_sample/mcp_client/client_async_simple.py`: cliente LangChain as铆ncrono que instancia `MultiServerMCPClient`, descubre herramientas `stdio` y crea un agente `ChatOpenAI` con prompt en espa帽ol.
- `mcp_sample/mcp_client/client_stdio_simple.py`: variante s铆ncrona via `stdio` puro, 煤til para depurar.
- `notebooks/`: espacio para experimentos o tutoriales pr谩cticos (no incluido en este README, pero recomendado para pruebas).
- `a2a/`: carpeta reservada para exploraciones adicionales (agents-to-agents, integraciones, etc.).

---

## 锔 C贸mo probar

1. **Instala dependencias m铆nimas**
   ```bash
   pip install langchain langchain-openai langchain-mcp-adapters fastmcp
   ```
2. **Lanza el servidor MCP local**
   ```bash
   python mcp_sample/mcp_server_local/server_local.py
   ```
3. **Ejecuta el cliente**
   ```bash
   python mcp_sample/mcp_client/client_async_simple.py
   ```
   Ver谩s c贸mo el agente:
   - Detecta las herramientas publicadas v铆a MCP.
   - Saluda al usuario.
   - Llama al sumador remoto para resolver `15 + 27`.

>  Usa cualquier endpoint compatible con la API de OpenAI (ej. [`lmstudio.ai`](https://lmstudio.ai), [`docker model runner (DMR)`](https://docs.docker.com/ai/model-runner/api-reference/)) u otros ajustando `base_url`, `model` y `api_key` en el cliente.

---

##  Recursos 煤tiles

- LangChain Agent Toolkit: https://python.langchain.com/docs/modules/agents/
- MCP reference impl (FastMCP): https://github.com/modelcontextprotocol/fastmcp
- Tutoriales oficiales MCP: https://modelcontextprotocol.io/tutorials
- Ejemplo multi-servidor LangChain + MCP: https://github.com/langchain-ai/langchain-mcp
